{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score # Cross Validation Score\n",
    "from sklearn.model_selection import GridSearchCV # Parameters of the Model\n",
    "from sklearn.model_selection import RandomizedSearchCV # Tuning the Parameters\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree Algo\n",
    "from sklearn.ensemble import RandomForestClassifier # Random Forest Algo.\n",
    "from sklearn.model_selection import train_test_split # helps in spliting the data in train and test set\n",
    "from sklearn.metrics import accuracy_score # Calculating the Accuracy Score againts the Classes Predicted vs Actuals.\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n"
     ]
    }
   ],
   "source": [
    "# Importing the Dataset\n",
    "cancer = pd.read_csv(\"data.csv\")\n",
    "cancer.head() # Previewing dataset\n",
    "\n",
    "columns=cancer.columns.tolist()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radius Mean Texture Mean Perimeter Mean Area Mean Smoothness Mean: Compactness Mean: Concavity Mean: Concave Points Mean: Symmetry Mean: Fractal Dimension Mean: \n",
    "\n",
    "# Remove 'id' and 'Unnamed: 32' columns\n",
    "cancer.drop(columns=['id','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst'], inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "X = cancer.drop(columns=['diagnosis'])\n",
    "y = cancer['diagnosis']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n"
     ]
    }
   ],
   "source": [
    "columns=cancer.columns.tolist()\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzing empty lists to append all model's name and corresponding name\n",
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "# Initialize DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "predicted = tree.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree's accuracy is 90.35087719298247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.94      0.90      0.92        69\n",
      "           M       0.85      0.91      0.88        45\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = metrics.accuracy_score(y_test,predicted)\n",
    "acc.append(x)\n",
    "model.append('Decision Tree')\n",
    "print(\"Decision Tree's accuracy is\", x * 100)\n",
    "\n",
    "print(classification_report(y_test,predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pickle.dump(tree,open('DecesionTree.pkl','wb'))\n",
    "model=pickle.load(open('DecesionTree.pkl','rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction using DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94736842 0.84210526 0.92982456 0.89473684 0.92982456 0.92982456\n",
      " 0.92982456 0.94736842 0.94736842 0.91071429]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(tree,X, y, cv = 10)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n"
     ]
    }
   ],
   "source": [
    "#['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', \n",
    "#'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "data = np.array([[13.54, 14.36, 87.46, 566.3, 0.09779, 0.08129, 0.06664, 0.04781, 0.1885, 0.05766]])\n",
    "prediction = tree.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Import ADABOOST & BAGGING Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagg = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Fit in the Bagging Classifier and See what do we get\n",
    "baggedmodel = bagg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions...\n",
    "pred_bagged = bagg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Accuracy\n",
    "accuracy_score(y_test, pred_bagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pickle.dump(bagg,open('Bagg.pkl','wb'))\n",
    "model=pickle.load(open('Bagg.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rfmodel = rf.fit(X_train, y_train)\n",
    "pred_RF = rf.predict(X_test)\n",
    "accuracy_score(y_test, pred_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pickle.dump(rf,open('RandomForest.pkl','wb'))\n",
    "model=pickle.load(open('RandomForest.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859649122807017"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "\n",
    "lgmodel = lg.fit(X_train, y_train)\n",
    "pred_LG = lg.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, pred_LG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B']\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[13.54, 14.36, 87.46, 566.3, 0.09779, 0.08129, 0.06664, 0.04781, 0.1885, 0.05766]])\n",
    "prediction = tree.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pickle.dump(lg,open('LogisticRegression.pkl','wb'))\n",
    "model=pickle.load(open('LogisticRegression.pkl','rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
